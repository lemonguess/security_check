# 项目开发思路

本文档旨在阐述本内容安全审核项目的核心开发思路，涵盖前端、后端、核心功能及技术选型等多个方面。

## 1. 前端页面开发

前端将构建一个简洁、直观的管理后台界面，用于展示审核任务的状态、结果，并提供手动触发审核、查看报告等功能。

-   **技术栈**: 考虑到快速开发和迭代，初期可采用 `Vue.js` 或 `React` 等现代前端框架，并搭配 `Element UI` 或 `Ant Design` 等成熟的组件库。
-   **核心功能**:
    -   **仪表盘**: 实时展示待审核、已通过、已违规的内容统计数据。
    -   **任务列表**: 分页展示所有审核任务，包括内容来源、类型、状态和审核结果。
    -   **内容详情**: 点击任务可查看原始内容（文本、图片、视频链接等）和 AI 审核给出的详细标签与建议。
    -   **手动操作**: 提供手动发起新内容审核的入口。

`static` 目录下的 `index.html`, `styles.css`, `script.js` 可作为快速原型或初期版本的基础。

## 2. 爬虫和审核功能设计

项目的核心是自动化地获取内容并进行审核。

-   **爬虫模块 (`services/spiders`)**:
    -   设计了针对不同内容源的爬虫，例如 `company_dynamic.py`（公司动态）、`current_political_news.py`（时政新闻）等。
    -   每个爬虫负责从指定网站抓取数据，并将数据标准化后存入数据库，等待后续处理。

-   **审核模块 (`apps/moderation.py`)**:
    -   这是内容审核的入口和协调中心。
    -   它会从数据库中获取待审核的内容，并调用相应的审核服务。
    -   `apps/checks.py` 可能定义了具体的审核规则和检查项。

-   **数据模型 (`models/models.py`)**:
    -   定义了内容、审核任务、审核结果等核心数据结构，并使用 ORM (如 SQLAlchemy) 与 `security_check.db` (SQLite) 数据库进行交互。

## 3. 异步处理审核任务

内容审核，特别是涉及视频、音频等多媒体文件的处理，可能是耗时操作。为避免阻塞主应用，必须采用异步任务处理机制。

-   **技术选型**: 推荐使用 `Celery` 作为任务队列，配合 `Redis` 或 `RabbitMQ` 作为消息代理（Broker）。
-   **实现流程**:
    1.  当爬虫抓取到新内容并存入数据库后，不是立即调用审核接口，而是创建一个异步审核任务，并将其推送到任务队列中。
    2.  `Celery` 的 Worker 进程会从队列中获取任务。
    3.  Worker 在后台调用 `moderation_service.py` 中定义的审核服务，与AI审核引擎进行交互。
    4.  审核完成后，Worker 将结果更新回数据库。
    5.  前端页面通过轮询或 WebSocket 感知任务状态的变化，并更新界面显示。

这种设计可以极大地提高系统的吞吐量和响应速度。

## 4. AI 技术在内容审核的应用

为提升审核的准确性与效率，本项目采用创新的 **AI 双引擎审核架构**，该架构不仅利用成熟的第三方AI服务，还引入了本地化大语言模型，形成优势互补。

### 4.1 AI 双引擎内容审核技术总结

-   **🎯 核心理念：双重保障 + 互补增强**
    -   通过 **AI 语义引擎** 和 **规则引擎** 的结合，实现更准确、更可靠的内容审核。AI负责理解复杂语义，规则引擎负责精准、快速匹配，二者结合，刚柔并济。

-   **🏗️ 架构设计**

    1.  **AI 语义引擎（第一重检测）**
        -   **技术实现**：基于 `Ollama` 部署的本地大语言模型（如 `qwen2.5-7b`），或集成 `services/aliyunsdk`、`services/wangyiyunsdk` 等云服务商的AI能力。
        -   **工作原理**：通过精心设计的中文提示词（Prompt），引导模型深度理解内容语义，能够有效识别上下文、隐喻、谐音变体等复杂表达。
        -   **输出**：返回结构化的 JSON 数据，包含风险等级、内容分类、置信度及判定原因。

    2.  **规则引擎（第二重检测）**
        -   **技术实现**：基于正则表达式和大规模敏感词库。
        -   **检测类型**：
            -   **敏感词匹配**：覆盖政治、暴力、色情等多个维度的分类词库。
            -   **隐私信息识别**：精准识别手机号、身份证、邮箱等个人敏感信息。
            -   **营销内容检测**：通过规则发现广告、垃圾信息。
        -   **优势**：响应速度极快，规则明确，逻辑清晰，可控性强。

    3.  **融合引擎（决策层）**
        -   **实现**：参考 `engines/fusion_engine.py` 的设计理念。
        -   **加权融合**：根据不同场景和内容类型，配置不同的权重比例，将两个引擎的结果进行加权合并。
        -   **智能决策**：
            -   **置信度计算**：综合两个引擎的置信度，生成最终的可信度评分。
            -   **行动建议**：根据融合后的结果，自动生成处理建议，如“通过”、“人工复审”或“直接拦截”。

### 4.2 关键技术特点

-   **互补性设计**：AI引擎擅长处理模糊和复杂的语义，而规则引擎擅长处理确定和精确的匹配。二者结合，完美互补。
-   **结构化输出**：所有引擎的输出都统一为标准化的JSON格式，便于后续处理和数据分析。
-   **异步并行处理**：两个引擎可并行运行，互不阻塞，有效提高了检测效率，支持对海量内容进行批量处理。
-   **配置驱动**：引擎的权重、敏感词库和检测规则均可通过配置文件动态调整，甚至支持热重载，使系统能灵活适应不同业务场景的需求。

### 4.3 多模态与智能化

-   **多模态审核**：架构同样支持对文本、图片、音/视频等多模态内容的审核。对于非文本内容，可先调用多媒体分析接口提取文本信息，再送入双引擎进行分析。
-   **智能代理**：`services/agents/moderation_agent.py` 可作为智能调度中心，根据内容类型和业务规则，动态选择最合适的审核链路（例如，简单文本直接走规则引擎，复杂长文案启用双引擎）。

## 5. 后端框架与项目结构设计

后端采用高度模块化和分层的设计理念，确保系统具备良好的可维护性、可扩展性和高性能。

### 5.1 技术选型与架构说明

-   **后端框架**：项目基于 FastAPI 构建，具备异步高效、类型安全、接口自动文档等优势，能够快速响应各类内容审核请求。
-   **数据模型管理**：采用 peewee 作为 ORM 框架，简洁易用，便于定义和维护数据表结构。
-   **数据库**：底层数据存储采用 SQLite，轻量级、易于部署，适合中小型内容审核场景。

### 5.2 项目结构与职责划分

-   `apps/`：核心业务逻辑模块，负责内容处理、审核流程编排、任务调度等。
-   `services/`：外部服务集成层，封装各类爬虫、AI SDK、第三方接口调用，提升代码复用性。
-   `engines/`：审核策略引擎，包括规则引擎、融合引擎等，负责内容风险判定与决策。
-   `models/`：数据模型定义与数据库交互，基于 peewee 实现所有表结构和数据操作。
-   `utils/`：通用工具库，包含日志、配置管理、异常处理、性能监控等辅助功能。
-   `config.py`：全局配置文件，集中管理数据库连接、服务参数、引擎权重等核心配置。

### 5.3 设计亮点与优势

-   **高内聚低耦合**：各模块职责单一，接口清晰，便于独立开发与维护。
-   **易于扩展**：支持按需增加新审核引擎、服务集成或业务流程，无需大幅重构。
-   **配置驱动**：系统核心参数均可通过配置文件灵活调整，适应不同业务场景。
-   **开发效率高**：FastAPI + peewee + SQLite 组合极大提升开发与部署效率，适合快速迭代和原型验证。

这种分层、解耦的结构使得各模块职责清晰，便于未来进行功能扩展和维护。