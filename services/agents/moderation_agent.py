"""
å†…å®¹å®¡æ ¸AIä»£ç†å®ç°
"""

import time
import json
import re
from typing import Dict, Any, List, Optional
import requests

import agentscope
from agentscope.agents import UserAgent
from agentscope.message import Msg
from agentscope.models import OllamaChatWrapper

from .base_agent import BaseAgent
from models.models import AIResult
from models.enums import RiskLevel, ContentCategory
from utils.exceptions import ModelError, TimeoutError
from utils.logger import get_logger
from utils.metrics import record_timing


class ModerationAgent(BaseAgent):
    """å†…å®¹å®¡æ ¸AIä»£ç†"""
    
    def __init__(
        self,
        name: str = "moderation_agent",
        model_config: Dict[str, Any] = None,
        timeout: float = 30.0,
        max_retries: int = 2
    ):
        super().__init__(name, model_config, timeout, max_retries)
        
        # ä¼˜åŒ–åçš„æç¤ºè¯æ¨¡æ¿
        self.system_prompt = self._create_system_prompt()
        
        # åˆå§‹åŒ–AgentScopeæ¨¡å‹
        self.model = None
        self.agent = None
        self._init_model()
    
    def _create_system_prompt(self) -> str:
        """åˆ›å»ºä¼˜åŒ–åçš„ç³»ç»Ÿæç¤ºè¯"""
        return """# è§’è‰²å®šä¹‰
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¸­æ–‡å†…å®¹å®¡æ ¸ä¸“å®¶ï¼Œä¸“æ³¨äºè¯†åˆ«å’Œåˆ†æå¯èƒ½è¿åä¸­å›½æ³•å¾‹æ³•è§„æˆ–ç¤¾åŒºå‡†åˆ™çš„å†…å®¹ã€‚ç‰¹åˆ«æ“…é•¿è¯†åˆ«å„ç§å˜å½¢è¡¨è¾¾ã€éšæ™¦è¡¨è¿°å’Œè§„é¿æ£€æµ‹çš„æ‰‹æ³•ã€‚

# æ ¸å¿ƒæŠ€èƒ½
- æ·±åº¦è¯­ä¹‰ç†è§£ä¸ä¸Šä¸‹æ–‡åˆ†æ
- æ•æ„Ÿå†…å®¹è¯†åˆ«ä¸é£é™©è¯„ä¼°
- å˜å½¢è¯æ±‡å’Œéšæ™¦è¡¨è¾¾è¯†åˆ«
- è§„é¿æ£€æµ‹æ‰‹æ³•è¯†åˆ«
- ç»“æ„åŒ–è¾“å‡ºä¸è¯æ®æå–
- ä¸­å›½æ³•å¾‹æ³•è§„å’Œç½‘ç»œå®‰å…¨çŸ¥è¯†

# å®¡æ ¸ç»´åº¦
è¯·ä»ä»¥ä¸‹ç»´åº¦åˆ†æå†…å®¹ï¼š
1. **æ”¿æ²»æ•æ„Ÿ** - æ¶‰åŠæ”¿æ²»ç«‹åœºã€æ”¿åºœæ”¿ç­–æ‰¹è¯„ã€ååŠ¨è¨€è®ºç­‰
2. **æš´åŠ›å†…å®¹** - æè¿°æš´åŠ›è¡Œä¸ºã€å¨èƒä»–äººç­‰
3. **è¿æ³•å†…å®¹** - æ¶‰åŠæ¯’å“ã€èµ°ç§ã€è¯ˆéª—ç­‰è¿æ³•æ´»åŠ¨
4. **æˆäººå†…å®¹** - è‰²æƒ…ã€æ€§æš—ç¤ºç­‰ä¸å½“å†…å®¹
5. **ä»‡æ¨è¨€è®º** - é’ˆå¯¹ç‰¹å®šç¾¤ä½“çš„æ­§è§†ã€ä»‡æ¨è¨€è®º
6. **è™šå‡ä¿¡æ¯** - æ˜æ˜¾çš„è°£è¨€ã€è™šå‡å®£ä¼ 
7. **åƒåœ¾ä¿¡æ¯** - å¹¿å‘Šæ¨å¹¿ã€è¥é”€å†…å®¹
8. **éªšæ‰°å†…å®¹** - äººèº«æ”»å‡»ã€æ¶æ„éªšæ‰°
9. **è¯ˆéª—ä¿¡æ¯** - é‡‘èè¯ˆéª—ã€å¥—è·¯è´·ç­‰
10. **éšç§æ³„éœ²** - åŒ…å«ä¸ªäººéšç§ä¿¡æ¯

# ç‰¹åˆ«å…³æ³¨çš„å˜å½¢è¡¨è¾¾æ‰‹æ³•
1. **ç¼©å†™æ›¿ä»£**: å¦‚ "xjp", "cxjp", "x j p", "c xjp" ç­‰è¡¨ç¤ºé¢†å¯¼äºº
2. **ç©ºæ ¼åˆ†ç¦»**: å¦‚ "æ‰“ å€’ x j p", "å…± äº§ å…š" ç­‰ç”¨ç©ºæ ¼åˆ†ç¦»æ•æ„Ÿè¯
3. **ç‰¹æ®Šå­—ç¬¦**: ä½¿ç”¨ç¬¦å·ã€æ ‡ç‚¹ç­‰æ›¿æ¢æ•æ„Ÿå­—ç¬¦
4. **æ‹¼éŸ³æ›¿ä»£**: ä½¿ç”¨æ‹¼éŸ³æˆ–æ‹¼éŸ³ç¼©å†™æ›¿ä»£ä¸­æ–‡ï¼Œå¦‚"xi"ä»£è¡¨"ä¹ "
5. **åŒéŸ³å­—æ›¿æ¢**: ä½¿ç”¨åŒéŸ³æˆ–è¿‘éŸ³å­—æ›¿ä»£æ•æ„Ÿè¯ï¼Œå¦‚"ä¹ è¿‘å¹³çŒª"ã€"åŒ…å­"ç­‰
6. **è¡¨æƒ…ç¬¦å·**: ä½¿ç”¨è¡¨æƒ…ç¬¦å·æ›¿ä»£æˆ–å½±å°„ï¼Œå¦‚"ä¹ è¿‘å¹³ğŸ·"ã€"ğŸ»"ç­‰
7. **è°éŸ³å½±å°„**: é€šè¿‡è°éŸ³æˆ–éŸ³ä¼¼çš„è¯æ±‡æš—ç¤ºæ•æ„Ÿå†…å®¹
8. **åŠ¨ç‰©ä»£ç§°**: ç”¨åŠ¨ç‰©åç§°ä»£æŒ‡ç‰¹å®šäººç‰©ï¼Œå¸¸è§çš„åŒ…æ‹¬"çŒª"ã€"ç†Š"ã€"åŒ…å­"ç­‰
9. **ä¸Šä¸‹æ–‡éšæ™¦**: é€šè¿‡ä¸Šä¸‹æ–‡æš—ç¤ºè€Œéç›´æ¥è¡¨è¿°
10. **åè¯è¡¨è¾¾**: é€šè¿‡åè¯æˆ–è®½åˆºè¡¨è¾¾æ•æ„Ÿè§‚ç‚¹
11. **è‹±æ–‡æ··åˆ**: ä¸­è‹±æ–‡æ··åˆè¡¨è¾¾æ•æ„Ÿå†…å®¹
12. **é”™åˆ«å­—**: æ•…æ„ä½¿ç”¨é”™åˆ«å­—æ¥è§„é¿æ£€æµ‹
13. **æ–‡å­—æ‹†åˆ†**: å°†æ•æ„Ÿè¯æ‹†åˆ†å¹¶æ’å…¥å…¶ä»–å­—ç¬¦ï¼Œå¦‚"æ‰“å°†å€’"å®é™…æ˜¯"æ‰“å€’"
14. **æ‹¼éŸ³æ··åˆ**: ä¸­æ–‡ã€æ‹¼éŸ³ã€è‹±æ–‡æ··åˆè¡¨è¾¾ï¼Œå¦‚"xiç»­daæ¨da"éšå«"ä¹ "å’Œ"æ‰“å€’"
15. **è¯­åºè°ƒæ•´**: è°ƒæ•´è¯åºæ¥éšè—æ•æ„Ÿè¡¨è¾¾ï¼Œå¦‚"å€’æ‰“"ã€"å°†å€’"ç­‰
16. **å†—ä½™å­—ç¬¦**: åœ¨æ•æ„Ÿè¯ä¸­æ’å…¥æ— æ„ä¹‰å­—ç¬¦æ¥å¹²æ‰°è¯†åˆ«

# é£é™©ç­‰çº§å®šä¹‰
- **safe** (0.0-0.2): å†…å®¹å®Œå…¨å®‰å…¨ï¼Œæ— ä»»ä½•æ•æ„Ÿé—®é¢˜
- **suspicious** (0.2-0.5): å†…å®¹å­˜åœ¨å¯ç–‘ä¹‹å¤„ï¼Œéœ€è¦å…³æ³¨
- **risky** (0.5-0.8): å†…å®¹å­˜åœ¨æ˜æ˜¾é£é™©ï¼Œå»ºè®®äººå·¥å®¡æ ¸
- **blocked** (0.8-1.0): å†…å®¹ä¸¥é‡è¿è§„ï¼Œåº”å½“é˜»æ­¢å‘å¸ƒ

# è¾“å‡ºè¦æ±‚
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡æœ¬ï¼š

```json
{
    "risk_level": "é£é™©ç­‰çº§ (safe/suspicious/risky/blocked)",
    "confidence_score": ç½®ä¿¡åº¦åˆ†æ•°(0.0-1.0),
    "categories": ["æ£€æµ‹åˆ°çš„åˆ†ç±»åˆ—è¡¨"],
    "suspicious_segments": ["å¯ç–‘ç‰‡æ®µåˆ—è¡¨"],
    "keywords_found": ["å‘ç°çš„å…³é”®è¯åˆ—è¡¨"],
    "evasion_techniques": ["è¯†åˆ«åˆ°çš„è§„é¿æŠ€æœ¯åˆ—è¡¨"],
    "reasoning": "è¯¦ç»†çš„åˆ†ææ¨ç†è¿‡ç¨‹ï¼ŒåŒ…æ‹¬å¯¹å˜å½¢è¡¨è¾¾çš„è§£é‡Š",
    "recommendations": ["å¤„ç†å»ºè®®åˆ—è¡¨"]
}
```

# åˆ†æåŸåˆ™
1. **æ·±åº¦è¯­ä¹‰åˆ†æ**: ä¸ä»…çœ‹è¡¨é¢è¯æ±‡ï¼Œæ›´è¦ç†è§£æ·±å±‚å«ä¹‰å’ŒçœŸå®æ„å›¾
2. **å˜å½¢è¯†åˆ«**: ç‰¹åˆ«å…³æ³¨å„ç§å˜å½¢ã€ç¼©å†™ã€åˆ†ç¦»ç­‰è§„é¿æ‰‹æ³•
3. **ä¸Šä¸‹æ–‡ç†è§£**: ç»“åˆå…¨æ–‡ä¸Šä¸‹æ–‡åˆ¤æ–­æ•æ„Ÿå†…å®¹çš„çœŸå®æ€§è´¨
4. **é£é™©è¯„ä¼°**: ç»¼åˆè€ƒè™‘å†…å®¹çš„å±å®³ç¨‹åº¦å’Œä¼ æ’­é£é™©
5. **è¯æ®å……åˆ†**: æä¾›å…·ä½“çš„æ–‡æœ¬è¯æ®å’Œè¯¦ç»†çš„åˆ†ææ¨ç†
6. **è°¨æ…å¤„ç†**: å¯¹äºæ¨¡ç³Šæƒ…å†µå€¾å‘äºè°¨æ…ï¼Œé¿å…è¯¯åˆ¤
7. **æŠ€æœ¯è¯†åˆ«**: è¯†åˆ«å¹¶è®°å½•ä½¿ç”¨çš„è§„é¿æ£€æµ‹æŠ€æœ¯

# ç‰¹åˆ«æé†’
- å³ä½¿æ˜¯çœ‹ä¼¼æ­£é¢çš„æ–°é—»æŠ¥é“ï¼Œä¹Ÿè¦ä»”ç»†æ£€æŸ¥æ˜¯å¦å¤¹æ‚äº†å˜å½¢çš„æ•æ„Ÿè¡¨è¾¾
- æ³¨æ„è¯†åˆ«åœ¨æ­£å¸¸å†…å®¹ä¸­ç©¿æ’çš„æ•æ„Ÿè¯æ±‡æˆ–è¡¨è¾¾
- å¯¹å­—æ¯ã€æ•°å­—ã€ç¬¦å·çš„ç»„åˆè¦ç‰¹åˆ«æ•æ„Ÿ
- ç©ºæ ¼åˆ†ç¦»çš„è¯æ±‡è¦é‡æ–°ç»„åˆåå†åˆ¤æ–­
- **é‡ç‚¹å…³æ³¨åŒéŸ³å­—å’Œè¡¨æƒ…ç¬¦å·**: "ä¹ è¿‘å¹³çŒª"ã€"ä¹ è¿‘å¹³ğŸ·"ã€"åŒ…å­"ã€"ğŸ»"ç­‰éƒ½æ˜¯å¸¸è§çš„å½±å°„è¡¨è¾¾
- **æ£€æŸ¥äººåä¸åŠ¨ç‰©çš„ç»„åˆ**: ç‰¹åˆ«æ˜¯é¢†å¯¼äººå§“ååè·ŸåŠ¨ç‰©åç§°æˆ–è¡¨æƒ…çš„æƒ…å†µ
- **åˆ†æè¡¨æƒ…ç¬¦å·çš„éšå«å«ä¹‰**: ğŸ·ã€ğŸ»ã€ğŸ¼ ç­‰è¡¨æƒ…åœ¨ç‰¹å®šä¸Šä¸‹æ–‡ä¸­å¯èƒ½æœ‰æ”¿æ²»éšå–»
- **è¯†åˆ«æ•…æ„çš„é”™åˆ«å­—**: å¦‚"çŒª"æ›¿ä»£æ­£å¸¸å­—ç¬¦ï¼Œæˆ–å…¶ä»–æ•…æ„çš„æ‹¼å†™é”™è¯¯
- **æ·±åº¦åˆ†ææ–‡å­—æ‹†åˆ†**: å¦‚"æ‰“å°†å€’"å¯èƒ½æ˜¯"æ‰“å€’"çš„å˜å½¢ï¼Œ"ç»§xiç»­"ä¸­çš„"xi"å¯èƒ½æŒ‡"ä¹ "
- **æ£€æŸ¥æ‹¼éŸ³æ··åˆè¡¨è¾¾**: "xi"ã€"da"ç­‰æ‹¼éŸ³å¯èƒ½éšå«æ•æ„Ÿè¯æ±‡ï¼Œç‰¹åˆ«æ˜¯ä¸æ•æ„ŸåŠ¨è¯ç»„åˆæ—¶
- **åˆ†æè¯­åºå¼‚å¸¸**: æ­£å¸¸è¯­æ³•ä¸é€šé¡ºçš„åœ°æ–¹å¯èƒ½éšè—æ•æ„Ÿè¡¨è¾¾
- **è¯†åˆ«å†—ä½™å­—ç¬¦å¹²æ‰°**: åœ¨è¯æ±‡ä¸­æ’å…¥"å°†"ã€"ç»§"ç­‰å­—ç¬¦å¯èƒ½æ˜¯ä¸ºäº†è§„é¿æ£€æµ‹
- **é‡æ„éšè—å¥å­**: å°è¯•ä»æ–‡æœ¬ä¸­é‡æ„å¯èƒ½çš„æ•æ„Ÿè¡¨è¾¾ï¼Œå¦‚ä»"æ‰“å°†å€’ç»§xiç»­daæ¨da"ä¸­è¯†åˆ«"æ‰“å€’ä¹ "

ç°åœ¨è¯·åˆ†æä»¥ä¸‹å†…å®¹ï¼š"""

    def _init_model(self):
        """åˆå§‹åŒ–AgentScopeæ¨¡å‹"""
        try:
            if self.model_config.get("type") == "ollama_chat":
                # ä½¿ç”¨Ollamaæ¨¡å‹
                self._init_ollama_model()
            else:
                # ä½¿ç”¨å…¶ä»–æ¨¡å‹
                self._init_agentscope_model()
                
        except Exception as e:
            self.logger.error(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè€Œæ˜¯è®¾ç½®ä¸ºNoneï¼Œè¿™æ ·ä¼šé™çº§ä½¿ç”¨ç›´æ¥APIè°ƒç”¨
            self.agent = None
            self.model = None
    
    def _init_ollama_model(self):
        """åˆå§‹åŒ–Ollamaæ¨¡å‹"""
        try:
            # åˆå§‹åŒ–AgentScope
            agentscope.init()
            
            # åˆ›å»ºOllamaæ¨¡å‹åŒ…è£…å™¨
            model_name = self.model_config.get("model_name", "qwen2.5:7b")
            host = self.model_config.get("api_base", "http://175.27.143.201:11434")
            
            self.model = OllamaChatWrapper(
                config_name="ollama_model",
                model_name=model_name,
                host=host,
                stream=False,
                options={
                    "temperature": self.model_config.get("temperature", 0.1),
                    "num_predict": self.model_config.get("max_tokens", 2000),
                },
                keep_alive="5m"
            )
            
            # åˆ›å»ºä»£ç†
            self.agent = UserAgent(
                name=self.name,
                model=self.model,
                sys_prompt=self.system_prompt
            )
            
            self.logger.info(f"Ollamaæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: {model_name}")
            
        except Exception as e:
            self.logger.error(f"Ollamaæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise ModelError(f"Ollamaè¿æ¥å¤±è´¥: {e}")
    
    def _init_agentscope_model(self):
        """åˆå§‹åŒ–AgentScopeæ ‡å‡†æ¨¡å‹"""
        try:
            # åˆå§‹åŒ–AgentScope
            agentscope.init()
            
            # è¿™é‡Œå¯ä»¥æ‰©å±•æ”¯æŒå…¶ä»–æ¨¡å‹
            self.logger.warning("æ ‡å‡†AgentScopeæ¨¡å‹æœªå®ç°ï¼Œè¯·ä½¿ç”¨Ollamaæ¨¡å‹")
            
        except Exception as e:
            self.logger.error(f"AgentScopeæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise ModelError(f"AgentScopeæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
    
    @record_timing("ai")
    def process(self, content: str, **kwargs) -> AIResult:
        """å¤„ç†å†…å®¹å®¡æ ¸"""
        start_time = time.time()
        
        try:
            self._validate_input(content)
            
            if self.agent:
                result = self._process_with_agentscope(content)
            else:
                result = self._process_with_ollama(content)
            
            processing_time = time.time() - start_time
            result.processing_time = processing_time
            result.model_name = self.model_config.get("model_name", "unknown")
            
            self._record_metrics(processing_time, "success")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            self.logger.error(f"å†…å®¹å¤„ç†å¤±è´¥: {e}")
            self._record_metrics(processing_time, "error")
            return self._create_default_result(content, f"å¤„ç†å¤±è´¥: {str(e)}")
    
    def _process_with_ollama(self, content: str) -> AIResult:
        """ä½¿ç”¨Ollamaå¤„ç†å†…å®¹"""
        api_base = self.model_config.get("api_base", "http://175.27.143.201:11434")
        model_name = self.model_config.get("model_name", "qwen2.5:7b")
        
        # æ„å»ºè¯·æ±‚
        prompt = f"{self.system_prompt}\n\nå†…å®¹ï¼š{content}"
        
        payload = {
            "model": model_name,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": self.model_config.get("temperature", 0.1),
                "num_predict": self.model_config.get("max_tokens", 2000),
            }
        }
        
        try:
            response = requests.post(
                f"{api_base}/api/generate",
                json=payload,
                timeout=self.timeout
            )
            response.raise_for_status()
            
            result_data = response.json()
            response_text = result_data.get("response", "")
            
            return self._parse_ai_response(response_text)
            
        except requests.exceptions.Timeout:
            raise TimeoutError(f"Ollamaè¯·æ±‚è¶…æ—¶ ({self.timeout}s)")
        except requests.exceptions.RequestException as e:
            raise ModelError(f"Ollamaè¯·æ±‚å¤±è´¥: {e}")
        except Exception as e:
            raise ModelError(f"Ollamaå¤„ç†å¤±è´¥: {e}")
    
    def _process_with_agentscope(self, content: str) -> AIResult:
        """ä½¿ç”¨AgentScopeå¤„ç†å†…å®¹"""
        try:
            # åˆ›å»ºæ¶ˆæ¯
            msg = Msg(name="user", content=content, role="user")
            
            # è·å–å›å¤
            response = self.agent(msg)
            response_text = response.content
            
            return self._parse_ai_response(response_text)
            
        except Exception as e:
            self.logger.error(f"AgentScopeå¤„ç†å¤±è´¥: {e}")
            raise ModelError(f"AgentScopeå¤„ç†å¤±è´¥: {e}")
    
    def _parse_ai_response(self, response_text: str) -> AIResult:
        """è§£æAIå“åº”"""
        try:
            # å°è¯•æå–JSON
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
                json_str = response_text.strip()
            
            data = json.loads(json_str)
            
            # æ˜ å°„é£é™©ç­‰çº§
            risk_level_map = {
                "safe": RiskLevel.SAFE,
                "suspicious": RiskLevel.SUSPICIOUS,
                "risky": RiskLevel.RISKY,
                "blocked": RiskLevel.BLOCKED
            }
            
            risk_level = risk_level_map.get(data.get("risk_level", "safe"), RiskLevel.SAFE)
            
            # æ˜ å°„åˆ†ç±»
            category_map = {
                "political": ContentCategory.POLITICAL,
                "violence": ContentCategory.VIOLENCE,
                "adult": ContentCategory.ADULT,
                "illegal": ContentCategory.ILLEGAL,
                "fraud": ContentCategory.FRAUD,
                "privacy": ContentCategory.PRIVACY,
                "hate_speech": ContentCategory.HATE_SPEECH,
                "harassment": ContentCategory.HARASSMENT,
                "spam": ContentCategory.SPAM,
                "misinformation": ContentCategory.MISINFORMATION
            }
            
            categories = [
                category_map.get(cat, ContentCategory.OTHER)
                for cat in data.get("categories", [])
                if cat in category_map
            ]
            
            # è®¡ç®—é£é™©åˆ†æ•°
            confidence = data.get("confidence_score", 0.5)
            risk_score = self._calculate_risk_score(risk_level, confidence)
            
            return AIResult(
                risk_level=risk_level,
                violated_categories=categories,
                risk_score=risk_score,
                risk_reasons=data.get("recommendations", []),
                detailed_analysis=data.get("reasoning", ""),
                confidence_score=confidence,
                suspicious_segments=data.get("suspicious_segments", []),
                keywords_found=data.get("keywords_found", []),
                evasion_techniques=data.get("evasion_techniques", []),
                reasoning=data.get("reasoning", ""),
                recommendations=data.get("recommendations", [])
            )
            
        except (json.JSONDecodeError, KeyError) as e:
            self.logger.warning(f"AIå“åº”è§£æå¤±è´¥ï¼Œä½¿ç”¨åå¤‡è§£æ: {e}")
            return self._fallback_parse(response_text)
    
    def _fallback_parse(self, response_text: str) -> AIResult:
        """åå¤‡è§£ææ–¹æ³•"""
        text_lower = response_text.lower()
        
        # ç®€å•çš„å…³é”®è¯æ£€æµ‹
        if any(keyword in text_lower for keyword in ["blocked", "ä¸¥é‡", "è¿è§„"]):
            risk_level = RiskLevel.BLOCKED
            risk_score = 0.8
        elif any(keyword in text_lower for keyword in ["risky", "é£é™©", "å±é™©"]):
            risk_level = RiskLevel.RISKY
            risk_score = 0.6
        elif any(keyword in text_lower for keyword in ["suspicious", "å¯ç–‘", "æ³¨æ„"]):
            risk_level = RiskLevel.SUSPICIOUS
            risk_score = 0.4
        else:
            risk_level = RiskLevel.SAFE
            risk_score = 0.1
        
        return AIResult(
            risk_level=risk_level,
            violated_categories=[],
            risk_score=risk_score,
            risk_reasons=["AIå“åº”è§£æå¤±è´¥ï¼Œä½¿ç”¨ç®€å•åˆ†æ"],
            detailed_analysis=response_text[:200] + "...",
            confidence_score=0.3,
            suspicious_segments=[],
            keywords_found=[],
            evasion_techniques=[],
            reasoning="åå¤‡è§£ææ–¹æ³•",
            recommendations=["å»ºè®®äººå·¥å¤æ ¸"]
        )
    
    def _calculate_risk_score(self, risk_level: RiskLevel, confidence: float) -> float:
        """æ ¹æ®é£é™©ç­‰çº§å’Œç½®ä¿¡åº¦è®¡ç®—é£é™©åˆ†æ•°"""
        base_scores = {
            RiskLevel.SAFE: 0.1,
            RiskLevel.SUSPICIOUS: 0.4,
            RiskLevel.RISKY: 0.7,
            RiskLevel.BLOCKED: 0.9
        }
        base_score = base_scores.get(risk_level, 0.5)
        # ç½®ä¿¡åº¦å½±å“æœ€ç»ˆåˆ†æ•°
        return min(base_score * confidence + 0.1, 1.0)
    
    def _create_default_result(self, content: str, error_msg: str) -> AIResult:
        """åˆ›å»ºé»˜è®¤é”™è¯¯ç»“æœ"""
        return AIResult(
            risk_level=RiskLevel.SUSPICIOUS,
            violated_categories=[],
            risk_score=0.5,
            risk_reasons=[error_msg],
            detailed_analysis=f"å¤„ç†å¤±è´¥: {error_msg}",
            confidence_score=0.1,
            suspicious_segments=[],
            keywords_found=[],
            evasion_techniques=[],
            reasoning=error_msg,
            recommendations=["å»ºè®®é‡è¯•æˆ–äººå·¥å®¡æ ¸"]
        )
    
    def _validate_input(self, content: str):
        """éªŒè¯è¾“å…¥å†…å®¹"""
        if not content or not content.strip():
            raise ValueError("å†…å®¹ä¸èƒ½ä¸ºç©º")
        if len(content) > 10000:
            raise ValueError("å†…å®¹é•¿åº¦ä¸èƒ½è¶…è¿‡10000å­—ç¬¦")
    
    def _record_metrics(self, processing_time: float, status: str):
        """è®°å½•æŒ‡æ ‡"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ æŒ‡æ ‡è®°å½•é€»è¾‘
        pass
    
    def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        try:
            if self.model_config.get("type") == "ollama_chat":
                api_base = self.model_config.get("api_base", "http://175.27.143.201:11434")
                response = requests.get(f"{api_base}/api/tags", timeout=5)
                if response.status_code == 200:
                    return {"status": "healthy", "model": "ollama", "api_base": api_base}
                else:
                    return {"status": "unhealthy", "error": f"HTTP {response.status_code}"}
            else:
                return {"status": "healthy", "model": "agentscope"}
        except Exception as e:
            return {"status": "unhealthy", "error": str(e)}


def create_moderation_agent(config: Dict[str, Any]) -> ModerationAgent:
    """åˆ›å»ºå†…å®¹å®¡æ ¸ä»£ç†å·¥å‚å‡½æ•°"""
    ai_config = config.get("ai", {})
    models_config = ai_config.get("models", {})
    default_model = ai_config.get("default_model", "ollama_qwen")
    
    # è·å–é»˜è®¤æ¨¡å‹é…ç½®
    model_config = models_config.get(default_model, {})
    
    return ModerationAgent(
        name="content_moderator",
        model_config=model_config,
        timeout=ai_config.get("timeout", 30.0),
        max_retries=ai_config.get("max_retries", 2)
    ) 